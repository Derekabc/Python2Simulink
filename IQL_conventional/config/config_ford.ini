[MODEL_CONFIG]
max_grad_norm = 40
gamma = 0.99
lr_init = 1e-4
lr_decay = constant
epsilon_init = 0.9
epsilon_min = 0.1
epsilon_decay = linear
epsilon_ratio = 0.5
num_fc = 128
num_h = 64
batch_size = 64
buffer_size = 1e6
reward_norm = 1.0
reward_clip = 5.0


[TRAIN_CONFIG]
total_step = 1.5e6
test_interval = 1e4
log_interval = 10000


[ENV_CONFIG]
sample_time = 0.2
episode_length = 765
# 1 for True and 0 for False
discrete = 1
rendering = 0
# objective is used to choose different reward functions
objective = max_flow
seed = 42
test_seeds = 10000,20000,30000